# -*- coding: utf-8 -*-
"""Homework3-MLDL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fe68eoZz767M492edkBimZ5o_K1C8hdo

**Install requirements**
"""

!pip3 install 'torch==1.3.1'
!pip3 install 'torchvision==0.5.0'
!pip3 install 'Pillow-SIMD'
# need tqdm version 4.30.0 for compatibility
!pip3 install 'tqdm==4.30.0'

"""**Import libraries**"""

import os
import logging

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Subset, DataLoader
from torch.backends import cudnn
from torch.autograd import Function
from torch.hub import load_state_dict_from_url

import torchvision
from torchvision import datasets, transforms

from PIL import Image
from tqdm import tqdm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import ParameterGrid
from google.colab import drive

from statistics import mean, stdev
from collections import defaultdict

"""**Set Arguments**"""

DEVICE = 'cuda' # 'cuda' or 'cpu'

NUM_CLASSES = 7 # Number of total classes of PACS dataset
NUM_DOMAINS = 4 # Number of total domains of PACS dataset

BATCH_SIZE = int(256 / 2)     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing
                     # the batch size, learning rate should change by the same factor to have comparable results

LR = 1e-3         # The initial Learning Rate
MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD
WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default

NUM_EPOCHS = int(20)     # Total number of training epochs (iterations over dataset)
STEP_SIZE = int(20)      # How many epochs before decreasing learning rate (if using a step-down policy)
GAMMA = 0.1          # Multiplicative factor for learning rate step-down

ALPHA = 0.03

LOG_FREQUENCY = 10

"""**Define Data Preprocessing**"""

# Define transforms for training phase
# Normalize ImageNet: https://github.com/pytorch/examples/blob/97304e232807082c2e7b54c597615dc0ad8f6173/imagenet/main.py#L197-L198
mean_imagenet = [0.485, 0.456, 0.406]
std_imagenet = [0.229, 0.224, 0.225]


transform = transforms.Compose([transforms.Resize(256), 
                                transforms.CenterCrop(size=224),  
                                transforms.ToTensor(),
                                transforms.Normalize(mean=mean_imagenet, std=std_imagenet)])

"""**Prepare Dataset**

Implemented Dataset
"""

class PACS:

    def __init__(self, root, transform=None):
        self.root = root

        # List of all domains sorted
        self.domains = sorted([d.name for d in os.scandir(self.root) if d.is_dir()])
        self.classes = sorted([d.name for d in os.scandir(os.path.join(self.root, self.domains[0])) if d.is_dir()])
        
        self.datasets = {}
        for domain in self.domains:
            domain_root = os.path.join(self.root, domain)
            self.datasets[domain] = (datasets.ImageFolder(domain_root, transform))

    def get_datasets(self):
        return self.datasets

    def get_classes(self):
        return self.classes

    def get_domains(self):
        return self.domains

from sklearn.model_selection import StratifiedShuffleSplit

# Clone github repository with data
if not os.path.isdir('./Homework3-PACS'):
    !git clone https://github.com/MachineLearning2020/Homework3-PACS

DATA_DIR = 'Homework3-PACS/PACS'

pacs_datasets = PACS(DATA_DIR, transform)

"""**Prepare Dataloaders**"""

# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)
photo_dataloader = DataLoader(pacs_datasets.datasets['photo'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last = True)
art_dataloader = DataLoader(pacs_datasets.datasets['art_painting'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last = True)
cartoon_dataloader = DataLoader(pacs_datasets.datasets['cartoon'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
sketch_dataloader = DataLoader(pacs_datasets.datasets['sketch'], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last = True)

"""In order to check the dataloaders."""

# As our images are normalized we have to denormalize them and 
# convert them to numpy arrays.
def imshow(img, title=None):
    img = img.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img = std*img + mean
    img = np.clip(img, 0, 1)
    plt.imshow(img)
    if title is not None:
        plt.title(title)
    plt.pause(0.001) #Pause is necessary to display images correctly
    

def image_analysis(dataset):
    class_counter = defaultdict(int)
    size_list = []
    
    for image, label_idx in dataset:
        size_list.append(image.size)
        label = dataset.classes[label_idx]
        class_counter[label] = class_counter[label] + 1
    return size_list, class_counter

#images, labels = next(iter(cartoon_dataloader))
#grid_img = torchvision.utils.make_grid(images[:4], nrow=4)
#imshow(grid_img, title=[cartoon_dataloader.dataset.classes[int(x)] for x in labels[:4]])

pacs_datasets_analysis = PACS(DATA_DIR)

size_list = []
domain_class_counter = {}
for dataset_key, dataset in pacs_datasets_analysis.datasets.items():
    print(str(dataset))
    l, domain_class_counter[dataset_key] = image_analysis(dataset)
    size_list = size_list + l

width = [i[0] for i in size_list]
height = [i[1] for i in size_list]

plt.hexbin(width, height, gridsize=30, cmap='Blues')
cb = plt.colorbar(label='count in bin')

pd.DataFrame(domain_class_counter).T.plot(kind='bar')
plt.show()
pd.DataFrame(domain_class_counter).plot(kind='bar')
plt.show()

"""**Prepare Network**"""

# Autograd Function objects are what record operation history on tensors,
# and define formulas for the forward and backprop.

class GradientReversalFn(Function):
    @staticmethod
    def forward(ctx, x, alpha):
        # Store context for backprop
        ctx.alpha = alpha
        
        # Forward pass is a no-op
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        # Backward pass is just to -alpha the gradient
        output = grad_output.neg() * ctx.alpha

        # Must return same number as inputs to forward()
        return output, None

model_urls = {
    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',
}

class AlexNetWithReverseGrad(nn.Module):
    # Implemented DANN on AlexNet
    def __init__(self, num_classes=1000):
        super(AlexNetWithReverseGrad, self).__init__()
        
        # Feature extractor: Convolutional Layers of AlexNet
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        
        # Label predictor: Fully Connected Layers of AlexNet
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

        # Discriminator
        self.dann_classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x, alpha=1.0):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        features = x
        reverse_features = GradientReversalFn.apply(x, alpha)
        
        class_pred = self.classifier(features)
        domain_pred = self.dann_classifier(reverse_features)
        return class_pred, domain_pred

def alexnet_rg(pretrained=False, progress=True, **kwargs):
    """
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    """
    model = AlexNetWithReverseGrad(**kwargs)
    if pretrained:
        state_dict = load_state_dict_from_url(model_urls['alexnet'], 
                                              progress=progress)
        model.load_state_dict(state_dict, strict=False)

        model.dann_classifier[1].weight.data = model.classifier[1].weight.data
        model.dann_classifier[1].bias.data = model.classifier[1].bias.data

        model.dann_classifier[4].weight.data = model.classifier[4].weight.data
        model.dann_classifier[4].bias.data = model.classifier[4].bias.data

        model.dann_classifier[6].weight.data = model.classifier[6].weight.data
        model.dann_classifier[6].bias.data = model.classifier[6].bias.data

    return model

"""**Prepare Model**"""

def prepare_model(lr, step_size=None, gamma=0.01, num_epochs=None, dann_scheduler=False):
    net = alexnet_rg(pretrained=True) # Loading AlexNet with reversed gradient model pretrained with ImageNet

    net.classifier[6] = nn.Linear(4096, NUM_CLASSES) 
    net.dann_classifier[6] = nn.Linear(4096, NUM_DOMAINS)

    # Define loss function
    criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy

    # Choose parameters to optimize
    parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet

    # Define optimizer
    optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)

    # Define scheduler
    if dann_scheduler and num_epochs != None:
        # This is the implementation of the DANN paper scheduler
        dann_scheduler_function = lambda epoch: 1 / pow(1 + 10 * float(epoch) / float(num_epochs), 0.75)
        scheduler = optim.lr_scheduler.LambdaLR(optimizer, dann_scheduler_function)
    elif step_size != None:
        #This is the normal scheduler, this one was used always
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
    else:
        raise Exception("Invalid arguments for model preparation")
  
    return net, criterion, optimizer, scheduler

"""**Load logging**"""

# Commented out IPython magic to ensure Python compatibility.
LOG_DIR = "runs_h3"

# In order to save the results in google drive.
drive.mount('/gdrive')
!ln -s "/gdrive/My Drive/Colab Notebooks/runs_h3" "/content/runs_h3"

# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir runs_h3/photo_art_dann/

"""**Prepare Train**"""

from torch.utils.tensorboard import SummaryWriter
from datetime import datetime

def train_model(net, log_folder, optimizer, scheduler, num_epochs, dl_source, 
                criterion_class, dl_target=None, criterion_domain=None, alpha=None):
    # By default, everything is loaded to cpu
    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda

    cudnn.benchmark # Calling this optimizes runtime

    # TensorboardX summary writer
    now = datetime.now()
    params_save = 'lr: {}, batch: {}, epochs: {}'.format(
        scheduler.get_last_lr()[0], dl_source.batch_size, 
        num_epochs)
    
    log_dir = os.path.join(log_folder, now.strftime('%m-%d %H:%M:%S, ') + params_save)
    tbwriter = SummaryWriter(log_dir=log_dir)

    # Select the max number of batches
    if dl_target == None:
        max_batches = len(dl_source)
    else:
        max_batches = min(len(dl_source), len(dl_target))

    current_step = 0
    # Start iterating over the epochs
    for epoch in range(num_epochs):
        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_last_lr()))

        # Get iterators from dataloaders
        source_iter = iter(dl_source)
        if dl_target != None:
            target_iter = iter(dl_target)

        # Iterate over the dataset
        for batch_idx in range(max_batches):
            
            if alpha == None:
                # Training progress and GRL lambda
                p = float(batch_idx + epoch * max_batches) / (num_epochs * max_batches)
                grl_lambda = 2. / (1. + np.exp(-10 * p)) - 1
            else:
                # A constant alpha was setted
                grl_lambda = alpha
            
            net.train() # Sets module in training mode

            optimizer.zero_grad() # Zero-ing the gradients

            # Train on source domain
            X_s, y_s = next(source_iter)
            X_s = X_s.to(DEVICE)
            y_s = y_s.to(DEVICE)

            class_pred, domain_pred = net(X_s, grl_lambda)
            loss_s_label = criterion_class(class_pred, y_s) # Gy loss (source)
            loss = loss_s_label

            if dl_target != None:
                # Compute the loss in source domain
                y_s_domain = torch.zeros(len(y_s), dtype=torch.long).to(DEVICE) # generate source domain labels
                loss_s_domain = criterion_domain(domain_pred, y_s_domain) # Gd loss (source)

                # Train on target domain
                X_t, _ = next(target_iter) # ignore target domain class labels!
                X_t = X_t.to(DEVICE)
                y_t_domain = torch.ones(len(y_s), dtype=torch.long).to(DEVICE) # generate target domain labels

                class_pred, domain_pred = net(X_t, grl_lambda)
                loss_t_domain = criterion_domain(domain_pred, y_t_domain) # Gd loss (target)
                loss = loss + loss_s_domain + loss_t_domain
          
            # Log the information and add to tensorboard
            if current_step % LOG_FREQUENCY == 0:
                with torch.no_grad():
                    _, preds = torch.max(class_pred, 1)
                    accuracy = torch.sum(preds == y_s) / float(len(y_s))
                    tbwriter.add_scalar('loss source label', loss_s_label.item(), current_step)
                    tbwriter.add_scalar('accuracy', accuracy.item(), current_step)
                    tbwriter.add_scalar('lambda', grl_lambda, current_step)
                    tbwriter.add_scalar('learning rate', scheduler.get_last_lr()[0], current_step)

                    if dl_target != None:
                        tbwriter.add_scalars(f'losses/check_info', {
                              'loss source label': loss_s_label.item(),
                              'loss sorce domain': loss_s_domain.item(),
                              'loss target domain': loss_t_domain.item()
                        }, current_step)

                        tbwriter.add_scalar('loss sorce domain', loss_s_domain.item(), current_step)
                        tbwriter.add_scalar('loss target domain', loss_t_domain.item(), current_step)
                        print('Epoch: {}\tStep: {}\tLoss label: {:.4f}   Acc: {:.4f}   '
                              'Loss sorce domain: {:.4f}   Loss target domain: {:.4f}'
                            .format(epoch + 1, current_step, loss_s_label.item(), 
                                    accuracy.item(), loss_s_domain.item(), 
                                    loss_t_domain.item()))
                    else:
                        print('Epoch: {}\tStep: {}\tLoss label: {:.4f} \tAcc: {}'
                            .format(epoch + 1, current_step, loss_s_label.item(), accuracy.item()))
                    

            # Compute gradients for each layer and update weights
            loss.backward()  # backward pass: computes gradients
            optimizer.step() # update weights based on accumulated gradients

            current_step += 1

        # Step the scheduler
        scheduler.step() 

    tbwriter.close()

"""**Prepare Test**"""

def test_model(net, test_dataloader):
    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda
    net.train(False) # Set Network to evaluation mode

    running_corrects = 0
    for images, labels in tqdm(test_dataloader):
      images = images.to(DEVICE)
      labels = labels.to(DEVICE)

      # Forward Pass
      class_pred, domain_pred = net(images)

      # Get predictions
      _, preds = torch.max(class_pred.data, 1)

      # Update Corrects
      running_corrects += torch.sum(preds == labels.data).data.item()

    # Calculate Accuracy
    accuracy = running_corrects / float(len(test_dataloader.dataset))

    print('\nTest Accuracy: {}'.format(accuracy))
    return accuracy

"""**3.A Train and Test without DANN**

Train on Photo domain
"""

net, criterion, optimizer, scheduler = prepare_model(LR, STEP_SIZE, GAMMA)

log_folder = os.path.join(LOG_DIR, 'photo_art')

train_model(net, log_folder, optimizer, scheduler, NUM_EPOCHS, photo_dataloader, criterion)

"""Test on Art domain"""

test_model(net, art_dataloader)

"""**3.B Train and Test with DANN Adaptation**"""

net, criterion, optimizer, scheduler = prepare_model(LR, STEP_SIZE, GAMMA)

"""Train jointly on the labeled task (Photo) and the unsupervised task (discriminating between Photo and Art painting),"""

log_folder = os.path.join(LOG_DIR, 'photo_art_dann')

train_model(net, log_folder, optimizer, scheduler, NUM_EPOCHS, 
            photo_dataloader, criterion, art_dataloader, criterion, ALPHA)

"""Test on Art domain"""

test_model(net, art_dataloader)

"""# 4. Cross Domain Validation"""

def grid_search_point_4(param_grid, log_folder, save_file=None, dann=False, resume_file=None):
    acc_list = []
    parameter_grid = list(ParameterGrid(param_grid))
    last_idx = 0
    
    if resume_file != None: 
        # For resuming a stoped grid search.
        df_results = pd.read_pickle(resume_file)
        if df_results['parameter_grid'].tolist() == parameter_grid:
            print('Resuming grid search...')
            acc_list = df_results['acc_list'].tolist()
            acc_list = [x for x in acc_list if str(x) != 'nan']
            last_idx = len(acc_list)
            print('Last index found: {} of {} in total, last parameters: {}'
                .format(last_idx, len(parameter_grid), parameter_grid[last_idx]))
        else:
            raise Exception("Cannot resume the grid search, the parameters are not the same.")
    
    for idx, param_dict in enumerate(parameter_grid[last_idx:]):
        # Start the grid search

        # Create the models for photo to cartoon, and photo to sketch
        net_PC, criterion_PC, optimizer_PC, scheduler_PC = prepare_model(param_dict['LR'], param_dict['step_size'], param_dict['gamma'])
        net_PS, criterion_PS, optimizer_PS, scheduler_PS = prepare_model(param_dict['LR'], param_dict['step_size'], param_dict['gamma'])
        log_folder_PC = os.path.join(log_folder,'cartoon/' + str(param_dict))
        log_folder_PS = os.path.join(log_folder,'sketch/' + str(param_dict))
        
        print('\n\n===========\n\nStarting training index: {} of {}, params: {}'
            .format(last_idx + idx, len(parameter_grid), parameter_grid[last_idx + idx]))
        
        if dann:
            # Train both models with domain adaptation
            train_model(net_PC, log_folder_PC, optimizer_PC, scheduler_PC, param_dict['num_epochs'], 
                        photo_dataloader, criterion_PC, cartoon_dataloader, criterion_PC, param_dict['alpha'])
            train_model(net_PS, log_folder_PS, optimizer_PS, scheduler_PS, param_dict['num_epochs'], 
                        photo_dataloader, criterion_PS, sketch_dataloader, criterion_PS, param_dict['alpha'])
        else:
            # Train without domain adaptation (both networks are the same)
            train_model(net_PC, log_folder_PC, optimizer_PC, scheduler_PC, param_dict['num_epochs'], 
                        photo_dataloader, criterion_PC)
            net_PS = net_PC
        
        # Compute the accuracy in the target domains
        accuracy_cartoon = test_model(net_PC, cartoon_dataloader)
        accuracy_sketch = test_model(net_PS, sketch_dataloader)
        acc_list.append((mean([accuracy_cartoon, accuracy_sketch]), 
                         stdev([accuracy_cartoon, accuracy_sketch])))
        
        if save_file != None:
            # Save the results in a file just in case
            pd.DataFrame({
                'parameter_grid': pd.Series(parameter_grid),
                'acc_list': pd.Series(acc_list)
            }).to_pickle(save_file)

    # Get the best parameters of the results
    best_idx = acc_list.index(max(acc_list, key=lambda item: item[0]))
    best_params = parameter_grid[best_idx]

    return best_params, acc_list

# With gdrive already mounted, link a folder to save the grid search
!ln -s "/gdrive/My Drive/Colab Notebooks/grid_h3" "/content/grid_h3"

"""**4.A Run a grid search on Photo to Cartoon and Photo to Sketch, without Domain Adaptation.**"""

# Sets of hyper parameters 
tuned_parameters = {
    'LR': [5e-5, 1e-4, 5e-4],
    'num_epochs': [10, 15, 20],
    'step_size': [5, 10],
    'gamma': [0.01, 0.05]
}

# Run the grid search while saving the partial results in the 'save_file'

log_folder = os.path.join(LOG_DIR, 'grid_photo_art/')

now = datetime.now()
log_folder = os.path.join(log_folder, now.strftime('%m-%d %H:%M/'))

save_file = './grid_h3/test.csv'
best_params, acc_list = grid_search_point_4(tuned_parameters, log_folder, save_file)

print(best_params)

# In order to get the results from a saved file

df_results = pd.read_pickle('./grid_h3/grid_normal/05-22 08:00.txt')
acc_list = df_results['acc_list'].tolist()
acc_list = [x for x in acc_list if str(x) != 'nan']
parameter_grid = list(ParameterGrid(tuned_parameters))

best_idx = acc_list.index(max(acc_list, key=lambda item: item[0]))
best_params = parameter_grid[best_idx]
print(best_params)
print(acc_list[best_idx])

"""**4.B Implement 3A with the best hyperparameters found in 4.A**"""

net, criterion, optimizer, scheduler = prepare_model(best_params['LR'], best_params['step_size'], best_params['gamma'])

log_folder = os.path.join(LOG_DIR, 'photo_art/best')

train_model(net, log_folder, optimizer, scheduler, best_params['num_epochs'], photo_dataloader, criterion)

test_model(net, art_dataloader)

"""**4.C Run a grid search on Photo to Cartoon and Photo to Sketch, with Domain Adaptation**"""

# Sets of hyper parameters 

tuned_parameters_dann = {
    'LR': [5e-5, 1e-4, 5e-4],
    'num_epochs': [10, 15, 20, 25],
    'step_size': [5, 10, 20],
    'gamma': [0.01, 0.05],
    'alpha': [0.01, 0.03, 0.05]
}

# Run the grid search while saving the partial results in the 'save_file'

log_folder = os.path.join(LOG_DIR, 'grid_photo_art_dann/')

now = datetime.now()
log_folder = os.path.join(log_folder, now.strftime('%m-%d %H:%M/'))

save_file = os.path.join('./grid_h3/grid_dann', now.strftime('%m-%d %H:%M.txt'))

best_params_dann, acc_list = grid_search_point_4(tuned_parameters_dann, log_folder, save_file, dann=True)

print(best_params_dann)

# In order to get the results from a saved file

df_results = pd.read_pickle('./grid_h3/grid_dann_con/05-21 21:40.txt')
acc_list = df_results['acc_list'].tolist()
acc_list = [x for x in acc_list if str(x) != 'nan']
parameter_grid = list(ParameterGrid(tuned_parameters_dann))

best_idx = acc_list.index(max(acc_list, key=lambda item: item[0]))
best_params_dann = parameter_grid[best_idx]
print(best_params_dann)
print(acc_list[best_idx])

# To resume a grid search

log_folder = os.path.join(LOG_DIR, 'grid_photo_art_dann/')

log_folder = os.path.join(log_folder, '05-20 09:05/')

now = datetime.now()
save_file = os.path.join('./grid_h3/grid_dann_con', now.strftime('%m-%d %H:%M.txt'))

if not os.path.exists('./grid_h3/grid_dann_con'):
    os.mkdir('./grid_h3/grid_dann_con')

resume_file = os.path.join('./grid_h3/grid_dann_con', '05-21 08:11.txt')

best_params, acc_list = grid_search_point_4(tuned_parameters_dann, log_folder, save_file, dann=True, resume_file=resume_file)

"""**4.D Implement 3B with the best hyperparameters found in 4C**"""

net, criterion, optimizer, scheduler = prepare_model(best_params_dann['LR'], best_params_dann['step_size'], best_params_dann['gamma'])

log_folder = os.path.join(LOG_DIR, 'photo_art_dann/best')

train_model(net, log_folder, optimizer, scheduler, best_params_dann['num_epochs'], 
            photo_dataloader, criterion, art_dataloader, criterion, best_params_dann['alpha'])

test_model(net, art_dataloader)